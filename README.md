# Nabla
## Introduction $\nabla$
Introducing Nabla, a simple neural network library that implements a Multi-layer Perceptron (MLP) from scratch. 

To begin, please install requirements.txt via the command 
```py
pip install -r requirements.txt
```

Please look at `demo.ipynb` for a demonstration of how the library works, how to train models, load datasets, and perform regression and classification experiments.

The main code is in `nabla/`, which contains the `nn.py` and `optim.py` files. `nn.py` includes the linear layer, activations, loss functions, and dropout. `optim.py` contains Stochastic Gradient Descent (SGD) and the Adam optimizer.

